# Ads
## [TikTok Creative Center](https://ads.tiktok.com/business/creativecenter/pc/en?rid=vcxdlcdh10o)
- [About TikTok Ads Manager](https://ads.tiktok.com/help/article/tiktok-ads-manager-intro?lang=en)
  * **Dashboard**: Allows you to track changes in performance and review ad account data such as active campaigns, budget spending, and charts for tracking ad performance over time.
  * **Campaign**: Review all campaigns, ad groups, and ads you have created.
  * **Tools**: You can choose from 6 options in the drop-down list to manage what goes into your ads and who you want to reach: Events, Creatives, Audiences, Catalogs, Comments, and Instant Pages.
  * **Analytics**: You can create custom reports, or use one of our reporting templates to go deeper into your ad insights. You can also schedule reports to generate at a specific time.

 - [Ads Manager Walk Through](https://ads.tiktok.com/i18n/dashboard/?aadvid=7393058749373546497)
   * Create a campaign by objectives 
    <img width="929" alt="Screenshot 2024-07-18 at 3 25 39 PM" src="https://github.com/user-attachments/assets/579dc9d2-6238-4df9-aa6f-039f9aa6e7a2">

   * Automated rules in Tools
    <img width="946" alt="Screenshot 2024-07-18 at 3 29 19 PM" src="https://github.com/user-attachments/assets/dcebcb93-c586-445b-b28e-94aa55a532aa">

   * Under [Analytics](https://ads.tiktok.com/i18n/audience-insight?aadvid=7393058749373546497)
    <img width="959" alt="Screenshot 2024-07-18 at 3 31 04 PM" src="https://github.com/user-attachments/assets/84ed57c3-5137-49bc-b2b0-f56b3b39f348">
    
- [Trending](https://ads.tiktok.com/business/creativecenter/pc/en?rid=vcxdlcdh10o)
  * Learn from the Top-Performance Ads
  * [Explore Top Ads on TikTok](https://ads.tiktok.com/business/creativecenter/inspiration/topads/pc/en?period=30&region=US)

- [About This Ad](https://ads.tiktok.com/business/creativecenter/topads/7340427969016102913/pc/en?countryCode=US&from=001110&period=30)
  * Ad performance Merics
     * **CTR (点击率)** is the number of clicks that your ad receives divided by the number of times your ad is shown: clicks ÷ impressions = CTR. For example, if you had 5 clicks and 100 impressions, then your CTR would be 5%.
     * **CVR (转化率)** is calculated by dividing the number of users who converted by the number of users who clicked on the ad, and then multiplying by 100. For example, if 1,000 users saw an ad and 15 users installed the advertised app, the CVR would be 1.5%.
     * **Click** 
     * **Conversion**
     * **Remain** 
    <img width="624" alt="Screenshot 2024-07-18 at 3 55 56 PM" src="https://github.com/user-attachments/assets/55942556-dd44-4eb2-a703-33424aea0049">

## [16 of the Best TikTok Tools to Improve Your Marketing](https://blog.hootsuite.com/tiktok-tools/)
## [广告创建与投放](https://school.oceanengine.com/product_help/content/668400000006/121544)
## [抖音广告设计与推送算法](https://www.admin5.com/article/20201110/974851.shtml)
### 1. Type of Ads & Billings
- 开屏广告
  * 打开APP时第一时间出现的全屏广告
  * 有更强的视觉冲击效果
  * 常见于流量和日活高的应用
    
  展现规则
  * 静态、动态和视频三类广告时间分别为3、4、5秒
  * 支持展示和落地页跳转
    
  计价方式
  * CPM (Cost per thousand / 千人成本): used to identify the cost of every 1,000 impressions on a particular ad
  * 按时间收费, 广告主根据投放时间出价，不受曝光次数影响
    
 
- 信息流广告
  * 信息流广告根据用户兴趣和上下文浏览来推送
  * 相比强曝光的广告形式更原生，定向更精准，
  * 可互动的特性也有利于用户加深品牌印象
    
  展现规则
  (一般是在第3-4位出现，按文字链跳转又分为以下三类。)
  * 落地页广告：跳转H5，常见于培训课程，广告主一般会利用表单来获取用户信息提高转化率。
  * 下载页广告：跳转应用下载页，常见于游戏、教育类APP。
  * 购物页广告：跳转电商平台店铺，常见于服饰、美妆、母婴等品牌
  
  计价方式
  * CPC（点击收费），竞价起步单价0.2元；
  * CPA（实际投放效果计价），按照电话咨询量、APP下载量、表单提交量进行计费。
  
- 挑战赛广告
  * 抖音挑战赛根据广告主需求进行定制推广，类似于话题，但设有专门的话题页面。
  * 常见的挑战赛常吸引用户使用指定贴纸拍摄上传视频，利用创意和互动来进行排名送出奖品，常见于美食类产品。

- 达人带货广告
  * 最初的达人带货限于视频植入或纯软广，抖音小店开通后，达人带货变得更加方便，在主屏上就可以进入小店完成下单转化。
  * 相比前几种广告，带货类广告的转化更加直接。

  展现规则
  * 视频植入或跳转抖音小店
 
  计价方式
  1）直接接触达人，计价由双方决定
  2）通过第三方平台接触达人，按照粉丝规模计价

### 2. 抖音广告后的字节系公司
- **Ads Platform 交易平台**——巨量引擎
  * 广告交易平台在广告生态中是面向广告主的，广告主可以在平台上完成广告购买流程。巨量引擎最早是服务于今日头条的广告投放，在头条版图扩大后，旗下的抖音、西瓜视频、懂车帝等营销资源均可以通过巨量引擎进行交易。
  * 依赖今日头条和抖音庞大的用户群体，巨量引擎积累了丰富的定向体系，将用户分为9大定向维度和1000+的人群种类，有利于广告主更精准的投放。
  * 在巨量引擎上，广告主可以直接完成上述的开屏、信息流和挑战赛三种广告交易。
- **撮合服务平台**——巨量星图、即合平台
  ##### [巨量星图]
  * 达人带货广告
  * 需求方可以根据官方给出的达人相关的巨量星图指数、粉丝数和预期播放量下单，付费方式可以按照实际转化效果付费或达人固定报价合作。
  * 供给方达人或MCN机构可以在平台注册接单。
  * 这一平台常用于红人带货的美妆、食品饮料等电商类产品，视频素材由达人制作，因此还可以搭配使用购物车、落地页等组件。
  * 以广告主为例，可以依据内容类型、报价、粉丝数、eCPM和付费方式对达人进行筛选，选定后就可以进入结算页面。
    
  ##### [即合平台] -> 广告工作室
  * 用于连接广告主和视频创作者，交易的是“视频素材”这个产品。
  * 即合平台上提供500、1500、2500元等不等价套餐：
    * 500元套餐，主打短平快创作方式，真人出镜，有产品功能讲解，点击率+117%，转化率+68%，转化成本-21%
    * 1500元套餐，，有产品解说风格／手绘风格／多机位精拍／情景演绎等多种创意形式，点击率+146%，转化率+54%，转化成本-47%
    * 2500元套餐，涵盖沙画／动画／真人短片／微电影等多个领域，点击率+212%，转化率+97%，转化成本-35%
      
- **小店商家服务平台**——抖店、巨量鲁班
  ##### [抖店]
  * 广告主可以选择目前账号下的视频进行推广，并选择“小店商品引流”这一期望项。
  * 选定推广商品后，可以依据地域、性别和年龄段选择投放受众。
  * 推广费用需要商家提前充值，并可以根据充值金额显示预估投放时长和覆盖人数，费用按日扣除。创建广告后，商家可以查看广告花费、广告播放数量和收益等数据。
    
  ##### [巨量鲁班]
  * 可以依托头条系营销资源进行投放，提供的服务相比自助广告会更加强调CTR、ROI等转化数据。
 
- **创作者视频推广平台**——抖+
  * 面向创作者的二次推广工具，本质上也是一种广告，创作者便是需求方。创作者选定已有视频后，可以选择期望提升目标、投放时长、定向方式和投放金额，平台会给出后续的增粉点击率、互动率等效果评估数据。
    
----------------------------------------------------------------

[抖音和小红书都在引领流行趋势，二者有何不同？](https://www.niaogebiji.com/article-672863-1.html)
1. 内容形式: 视频VS笔记
2. 内容分发逻辑: 算法VS互动
3. 引领趋势源头：个人VS话题
4. 持续时间：长VS短
5. 覆盖人群：广泛VS垂直
6. 商业模式：电商VS广告
   
* 抖音的电商模式使其在流行趋势的快速变现上具有优势，而小红书的广告模式则更注重长期品牌价值的培养和用户的深度参与。
* 对于追求快速曝光和短期内实现销售转化的品牌，抖音是一个更为合适的选择；而对于那些注重品牌形象长期建设和深度用户关系维护的品牌，则可以考虑在小红书上进行更为深入的内容营销。

----------------------------------------------------------------

[怎样设计一个广告系统]([https://www.niaogebiji.com/article-672863-1.html](https://developer.aliyun.com/article/1110460)
> 百货店大亨约翰·沃纳梅克(John Wanamaker)在 100 多年前曾经说过：“我花在广告上的钱有一半是浪费的，但问题是我不知道是哪一半。”

衡量广告效果的标准取决于能够提高公司盈利能力的算法/广告引擎。广告行业所需要的核心能力是算法能力、工程能力、商业理解能力。

<img width="585" alt="Screenshot 2024-07-19 at 1 36 51 PM" src="https://github.com/user-attachments/assets/257b0e9b-b9af-4e43-97c3-dae5746acf15">

1. 品牌认知度（Brand Awareness）： 消费者对品牌的认知度，这是推广新产品的关键步骤。
2. 触达（Reach）： 通过活动可以接触到的潜在客户的估计数量。
3. 参与度（Engagement）： 创造性的想法能够让人们参与进来，并随着时间的推移创造出有意义的互动。
4. 发帖参与度（Post Engagement）： 人们在 Facebook 页面上与他人的互动次数，可以是任何形式的互动，从点赞到评论，再到分享。
5. 页面喜欢（Page Likes）： 人们希望看到你的促销活动、产品或在 Facebook 页面上发布的任何东西。
6. 事件响应（Event Responses）： 有兴趣或打算支持 Facebook 事件的人数。
7. 流量（Traffic）： 访问网站、Facebook 页面或点击链接的访客数量。
8. 潜在客户数（Lead Generation）： 增加未来销售的潜在客户的数量
9. 转化（Conversion）： 客户完成了订购，贡献了销售额

<img width="553" alt="Screenshot 2024-07-19 at 1 37 40 PM" src="https://github.com/user-attachments/assets/7f584285-f6c0-4df6-ba40-920b9af0dccf">


#### 目标客户群(标准)
1. 位置（Location）： 可以选择在特定国家或特定城镇的特定半径内显示广告，可以点选想要的地区。
2. 年龄（Age）： 对于 B2B 客户来说，他们不太可能将目标用户锁定在 21 岁以下的用户，因此这是一个很好的特性。此外，还可以针对不同的受众，或根据产品特性，针对多个年龄范围。
3. 性别（Gender）： 可以瞄准特定性别的人群，专注于核心用户，这个功能是为性别导向的产品设计的。
4. 详细目标（Detailed Targeting）： 这一功能是针对特定的兴趣，行为和人口统计数据，在 Facebook 用户数据中打过特殊的标签，从而可以将潜在受众最大化。
5. 联系（Connections）： 这个功能是针对那些没有联系你，或者与你有联系的人。这样做的目的是为了从现有的粉丝那里获得更多的信息从而获得更多新用户。
6. 语言（Languages）： 该特性根据用户设置的语言来定位用户。使用特定语言的人群有自己的文化，你的产品也许正好可以迎合这一人群。
7. 放置（Placements）： 这是为了最大化你的预算，通过多个网页向尽可能多的用户展示你的广告，或者可以选择特定网页来展示广告。
8. 活动设置（Campaign settings）： 用来决定你的活动的每日预算。
9. 预算（Budget）： 总体预算或者每日预算的选择。
10. 投标（Bidding）： 设置最低成本。
11. 创意（Creatives）： 使用各种图片、视频和动态 gif 来吸引用户的注意。

----------------------------------------------------------------
## [[学习资料] 在线广告系统](https://www.1point3acres.com/bbs/thread-890389-1-1.html)
### [Facebook Advertising System Design & Architecture](https://interviewnoodle.com/facebook-advertising-system-design-architecture-7eed10e68333)

<img width="908" alt="Screenshot 2024-07-19 at 1 43 29 PM" src="https://github.com/user-attachments/assets/dadbbfc5-6908-4dca-8e78-c4dd47d8dd95">

----------------------------------------------------------------

## System Design Interview: Design an Ad Click Aggregator 
https://www.hellointerview.com/learn/system-design/answer-keys/ad-click-aggregator

**Ad Click Aggregator** is a system that collects and aggregates data on ad clicks. It is used by advertisers to track the performance of their ads and optimize their campaigns. 

<img width="939" alt="Screenshot 2024-07-18 at 4 41 29 PM" src="https://github.com/user-attachments/assets/05aab247-9be3-4963-868f-ca76c24bf95a">



#### Functional Requirements 
1. Users can click on an ad and be redirected to the advertiser's website
2. Advertisers can query ad click metrics over time with a minimum granularity of 1 minute
3. Ad targeting
4. Ad serving
5. Cross device tracking
6. Integration with offline marketing channels

#### Non-Functional Requirements
1. Scalable to support a peak of 10k clicks per second
2. Low latency analytics queries for advertisers (sub-second response time)
3. Fault tolerant and accurate data collection. We should not lose any click data.
4. As realtime as possible. Advertisers should be able to query data as soon as possible after the click.
5. Idempotent click tracking. We should not count the same click multiple times.

(Optional)
6. Fraud or spam detection **
7. Demographic and geo profiling of users **
8. Conversion tracking **

<img width="937" alt="Screenshot 2024-07-18 at 4 42 10 PM" src="https://github.com/user-attachments/assets/8549bb28-8d55-4a58-a204-f31c174e68ea">


#### API / System Interface
* Input: 
  1. Click Data
  2. Advertiser Query
   
* Output:    
  1. Redirect 
  2. Aggregrated Click Metrcis

### Data Flow 
1. User clicks on an ad on a website.
2. The click is tracked and stored in the system.
3. The user is redirected to the advertiser's website.
4. Advertisers query the system for aggregated click metrics.


### High-Level Design
#### 1) Users can click on ads and be redirected to the target
When a user clicks on an ad which was placed by the **Ad Placement Service**, we will send a request to our `/click` endpoint, which will track the click and then redirect the user to the advertiser's website.

 * Two ways we can handle this redirect
 1) **Client side redirect:** When a user clicks on the ad, the browser will automatically redirect them to the target URL. The downside with this approach is that users could go to an advertiser's website without us knowing about it.
 2) **Server side redirect:** A more robust solution is to have the user click on the ad, which will then send a request to our server. Our server can then track the click and respond with a redirect to the advertiser's website via a 302 (redirect) status code. This way, we can ensure that we track every click and provide a consistent experience for users and advertisers. This approach also allows us to append additional tracking parameters to the URL
    
<img width="939" alt="Screenshot 2024-07-18 at 5 52 25 PM" src="https://github.com/user-attachments/assets/0327e240-a51c-4bd3-b164-720005f171c3">


#### 2) Advertisers can query ad click metrics over time at 1 minute intervals
Our users were successfully redirected, now let's focus on the advertisers. They need to be able to quickly query metrics about their ads to see how they're performing.

### *A simple design* will be have a single Click DB send data to the query service; 
There are lots of DB can be choosed, one way is to use Cassandra/(Amazon Keyspaces), where it was `write` optimazied in which it can support fast insertion & table updates.

<img width="941" alt="Screenshot 2024-07-18 at 5 15 08 PM" src="https://github.com/user-attachments/assets/85ed329e-e212-4f5b-92b4-f419e84081f7">


### *A better design* is to separate Analytics Database with Batch Processing

When a click comes in, we will store the raw event in our event database. Then, in batches, we can process the raw events and aggregate them into a separate database that is special optimized for querying. When an advertiser wants to query metrics, we simply query this analytics database for the metrics that they need. This allows us to provide low latency queries since we did the expensive aggregation work in advance.

#### NonFunc1. Scalable to support a peak of *10k clicks** per second
> How much data will we be processing exactly? If we have 10k clicks per second and we choose to run our batch processing every 5 minutes, we will be processing 3M events every minute. Each event will only be a hundred bytes at most, so we will be processing 300MB of data every minute. This is well within the capabilities of Spark.

To **reduce contention** (aka. resource competiton) for separating heavy database writes/reads, and to support **fault isolation** in which 1 database down will not affect the other database serving.

<img width="939" alt="Screenshot 2024-07-18 at 5 13 38 PM" src="https://github.com/user-attachments/assets/2bf2f656-4717-4208-8f8a-db688780aa82">

Using map-reduce, **Spark** will read the raw events in parallel chunks, aggregate them by ad ID and minute timestamp, and then write the aggregated data to our analytics database.

For an analytics database, we want a technology that is optimized for reads and aggregations. Online analytical processing **(OLAP) databases like Redshift, Snowflake, or BigQuery** are all good choices here. They are optimized for these types of queries and can handle the large volume of data that we will be storing.

### *A greatest design* is to run Real-time Analytics With Stream Processing
To address the latency and scalability issues, let's introduce a stream for real-time processing. This system allows us to process events as they come in, rather than waiting for a batch job to run.

When a click comes in our click processing service will immediately write the event to a stream like **Kafka or Kinesis**. We then need a stream processor like **Flink or Spark Streaming** to read the events from the stream and aggregate them in real-time.

This works by keeping a running count of click totals in memory and updating them as new events come in. When we reach the end of a time window, we can flush the aggregated data to our OLAP database.

![ddd](https://github.com/user-attachments/assets/91ddf63c-983d-4132-93f3-ead6b8759986)


### Deep Dive (Non Functional Requirement)
#### 1) How can we scale to support 10k clicks per second?
#### NonFunc1. Scalability 
* **Click Processor Service**: We can easily scale this service **horizontally by adding more instances**. Most modern cloud providers like AWS, Azure, and GCP provide managed services that automatically scale services based on CPU or memory usage. We'll need a load balancer in front of the service to distribute the load across instances.

* **Stream**: Both Kafka and Kinesis are distributed and can handle a large number of events per second but need to be properly configured. Kinesis, for example, has a limit of 1MB/s or 1000 records/s per shard, so we'll need to add some sharding. **Sharding by AdId** is a natural choice, this way, the stream processor can read from multiple shards in parallel since they will be independent of each other (all events for a given AdId will be in the same shard).

* **Stream Processor**: The stream processor, like Flink, can also be scaled **horizontally by adding more tasks or jobs**. We'll have a seperate Flink job reading from each shard doing the aggregation for the AdIds in that shard.

* **OLAP Database**: The OLAP database can be scaled **horizontally by adding more nodes**. While we could **shard by AdId**, we may also consider sharding by AdvertiserId instead. In doing so, all the data for a given advertiser will be on the same node, making queries for that advertiser's ads faster. This is in anticipation of advertisers querying for all of their active ads in a single view. Of course, it's important to monitor the database and query performance to ensure that it's meeting the SLAs and adapting the sharding strategy as needed.

> **Hot Shards**
> With the above scaling strategies, we should be able to handle a peak of 10k clicks per second. There is just one remaining issue, hot shards. Consider the case where Nike just launched a new Ad with Lebron James. This Ad is getting a lot of clicks and all of them are going to the same shard. This shard is now overwhelmed, which increases latency and, in the worst case, could even cause data loss.

> To solve the hot shard problem, we need a way of further partitioning the data. One popular approach is to update the partition key by appending a random number to the AdId. We could do this only for the popular ads as determined by ad spend or previous click volume. This way, the partition key becomes AdId:0-N where N is the number of additional partitions for that AdId.

#### 2) How can we ensure that we don't lose any click data?
#### NonFunc3. Fault tolerant and accurate data collection
The first thing to note is that we are already using a stream like **Kafka** or Kinesis to store the click data. By default, these streams are distributed, fault-tolerant, and highly available. They replicate data across multiple nodes and data centers, so even if a node goes down, the data is not lost. Importantly for our system, they also allow us to enable persistent storage, so even if the data is consumed by the stream processor, it is still stored in the stream for a certain period of time.

We can configure a *retention period of 7 days*, for example, so that if, for some reason, our stream processor goes down, it will come back up and can read the data that it lost from the stream again.

Stream processors like Flink also have a feature called *checkpointing*. This is where the processor periodically writes its state to a persistent storage like **S3**. If it goes down, it can read the last checkpoint and resume processing from where it left off. 

<img width="920" alt="Screenshot 2024-07-18 at 6 04 16 PM" src="https://github.com/user-attachments/assets/3cf7ceda-127d-416c-afe4-0e0c8f24ee84">

### *Reconciliation* matters!
> We should not lose any click data. Click data matters, a lot. If we lose click data, we lose money.

We need to make sure that our data is correct. This is a tough balance, because guaranteeing correctness and low latency are often at odds. We can balance the two by introducing *periodic reconciliation*.

Despite our best efforts with the above measures, things could still go wrong. Transient processing errors in Flink, bad code pushes, out-of-order events in the stream, etc., could all lead to slight inaccuracies in our data. To catch these, we can introduce a *periodic reconciliation job that runs every hour or day*.

![kk](https://github.com/user-attachments/assets/04a4c64d-8432-4543-9e4c-c26dcbf9963f)

At the end of the stream, alongside the stream processors, we can also dump the raw click events to a data lake like S3. **Flink** supports this through its FileSystem interface and various **connectors**, allowing for both batch and **real-time data processing output**s to be stored directly in **S3 buckets**. Then, as with the "good" answer in **"Advertisers can query ad click metrics over time at 1-minute intervals"** above, we can run a **batch job** that reads all the raw click events from the data lake and re-aggregates them. This way, we can **compare** the results of the batch job to the results of the stream processor and ensure that they match.

This essentially combines our two solutions, real-time stream processing and periodic batch processing, to ensure that our data is not only fast but also accurate.

### 3) How can we prevent abuse from users clicking on ads multiple times? 
> Generate a Unique impression ID

**Ad Placement Service** generate a *unique impression ID for each ad instance shown to the user*. This impression ID would be sent to the browser along with the ad and will serve as an idempotency key. When the user clicks on the ad, the browser sends the impression ID along with the click data. This way we can **dedup** clicks based on the impression ID.

> What is an Impression? An ad impression is a metric that represents the display of an ad on a web page. It is counted when the ad is fetched from its source and displayed on the user's screen. If we showed the same user the same ad multiple times in multiple places, then each of these placements is a new impression.

#### How do we dedup?
We should dedup *before* we put the click in the stream (Flink). When a click comes in, we check if the impression ID exists in a **cache**. If it does, then its a duplicate and we ignore it. If it doesn't, then we put the click in the stream and add the impression ID to the cache.

Morever, if a malicious user could send a bunch of fake clicks with falsified impression IDs, we can *sign the impression ID with a secret key* before sending it to the browser. When the click comes in, we can verify the signature to ensure the impression ID is valid before checking the cache.

![mmm](https://github.com/user-attachments/assets/12c5d36e-6557-4135-b2ec-dabcf55c9f13)

Let's recap:
* **Ad Placement Service** generates a **unique impression ID** for each ad instance shown to the user.
* The impression ID is signed with **a secret key** and sent to the browser along with the ad.
* When the user clicks on the ad, the browser sends the impression ID along with the click data.
* **The Click Processor** verifies the **signature** of the impression ID.
* **The Click Processor** checks if the impression ID **exists in a cache**. If it does, then it's a duplicate, and we ignore it. If it doesn't, then we put the click in the stream and add the impression ID to the cache.

### 4) How can we ensure that advertisers can query metrics at low latency?
#### NonFunc2. Low latency analytics queries
Query can still be slow is when we are aggregating over **larger time windows**, like a days, weeks, or even years. In this case, we can **pre-aggregate** the data in the **OLAP database**. This can be done by creating a new table that stores the aggregated data at a higher level of granularity, like daily or weekly.

> Pre-aggregating the data in the OLAP database is a common technique to improve query performance. It can be thought of similar to a form of caching. We are trading off storage space for query performance for the most common queries.




